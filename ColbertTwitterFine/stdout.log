2022-06-06 00:26:04,116 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'bert_model_name': 'bert-base-uncased', 'token_indexers': {'bert': {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'}}, 'type': 'mishra_reader'} and extras {}
2022-06-06 00:26:04,117 - INFO - allennlp.common.params - dataset_reader.type = mishra_reader
2022-06-06 00:26:04,117 - INFO - allennlp.common.from_params - instantiating class <class 'my_library.dataset_readers.mishra_reader_bert.SarcasmDatasetReader'> from params {'bert_model_name': 'bert-base-uncased', 'token_indexers': {'bert': {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'}}} and extras {}
2022-06-06 00:26:04,117 - INFO - allennlp.common.params - dataset_reader.lazy = False
2022-06-06 00:26:04,117 - INFO - allennlp.common.params - dataset_reader.seq_len = 10000
2022-06-06 00:26:04,117 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased
2022-06-06 00:26:04,117 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'} and extras {}
2022-06-06 00:26:04,118 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = bert-pretrained
2022-06-06 00:26:04,118 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer from params {'pretrained_model': 'bert-base-uncased'} and extras {}
2022-06-06 00:26:04,118 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.pretrained_model = bert-base-uncased
2022-06-06 00:26:04,118 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.use_starting_offsets = False
2022-06-06 00:26:04,118 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.do_lowercase = True
2022-06-06 00:26:04,118 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.never_lowercase = None
2022-06-06 00:26:04,118 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_pieces = 512
2022-06-06 00:26:04,419 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ubuntu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2022-06-06 00:26:04,757 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ubuntu/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2022-06-06 00:26:04,786 - INFO - allennlp.common.params - validation_dataset_reader = None
2022-06-06 00:26:04,786 - INFO - allennlp.common.params - train_data_path = data/Train1.csv
2022-06-06 00:26:04,786 - INFO - my_library.training.transfer - Reading training data from data/Train1.csv
2022-06-06 00:26:04,788 - INFO - my_library.dataset_readers.mishra_reader_bert - Reading instances from lines in file at: data/Train1.csv
2022-06-06 00:26:05,158 - INFO - allennlp.common.params - validation_data_path = data/Val1.csv
2022-06-06 00:26:05,158 - INFO - my_library.training.transfer - Reading validation data from data/Val1.csv
2022-06-06 00:26:05,159 - INFO - my_library.dataset_readers.mishra_reader_bert - Reading instances from lines in file at: data/Val1.csv
2022-06-06 00:26:05,248 - INFO - allennlp.common.params - test_data_path = data/Test1.csv
2022-06-06 00:26:05,249 - INFO - my_library.training.transfer - Reading test data from data/Test1.csv
2022-06-06 00:26:05,249 - INFO - my_library.dataset_readers.mishra_reader_bert - Reading instances from lines in file at: data/Test1.csv
2022-06-06 00:26:05,298 - INFO - my_library.training.transfer - From dataset instances, train, validation, test will be considered for vocabulary creation.
2022-06-06 00:26:05,298 - INFO - allennlp.common.params - vocabulary.type = None
2022-06-06 00:26:05,298 - INFO - allennlp.common.params - vocabulary.extend = False
2022-06-06 00:26:05,298 - INFO - allennlp.common.params - vocabulary.directory_path = None
2022-06-06 00:26:05,298 - INFO - allennlp.common.params - vocabulary.min_count = None
2022-06-06 00:26:05,298 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None
2022-06-06 00:26:05,298 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')
2022-06-06 00:26:05,299 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None
2022-06-06 00:26:05,299 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False
2022-06-06 00:26:05,299 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None
2022-06-06 00:26:05,299 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-06-06 00:26:05,306 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'bert_model_name': 'bert-base-uncased', 'type': 'bert_classifier'} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7ff975763f28>}
2022-06-06 00:26:05,306 - INFO - allennlp.common.params - model.type = bert_classifier
2022-06-06 00:26:05,307 - INFO - allennlp.common.params - model.bert_model_name = bert-base-uncased
2022-06-06 00:26:05,307 - INFO - allennlp.common.params - model.initializer = []
2022-06-06 00:26:05,307 - INFO - allennlp.common.params - model.regularizer = []
2022-06-06 00:26:05,639 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/ubuntu/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
2022-06-06 00:26:05,640 - INFO - transformers.configuration_utils - Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30522
}

2022-06-06 00:26:05,948 - INFO - transformers.modeling_utils - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/ubuntu/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
2022-06-06 00:26:08,578 - INFO - allennlp.nn.initializers - Initializing parameters
2022-06-06 00:26:08,579 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-06-06 00:26:08,579 - INFO - allennlp.nn.initializers -    linear.bias
2022-06-06 00:26:08,579 - INFO - allennlp.nn.initializers -    linear.weight
2022-06-06 00:26:08,579 - INFO - allennlp.nn.initializers -    text_field_embedder.embeddings.LayerNorm.bias
2022-06-06 00:26:08,579 - INFO - allennlp.nn.initializers -    text_field_embedder.embeddings.LayerNorm.weight
2022-06-06 00:26:08,579 - INFO - allennlp.nn.initializers -    text_field_embedder.embeddings.position_embeddings.weight
2022-06-06 00:26:08,579 - INFO - allennlp.nn.initializers -    text_field_embedder.embeddings.token_type_embeddings.weight
2022-06-06 00:26:08,579 - INFO - allennlp.nn.initializers -    text_field_embedder.embeddings.word_embeddings.weight
2022-06-06 00:26:08,579 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.0.attention.output.LayerNorm.bias
2022-06-06 00:26:08,579 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.0.attention.output.LayerNorm.weight
2022-06-06 00:26:08,579 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.0.attention.output.dense.bias
2022-06-06 00:26:08,579 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.0.attention.output.dense.weight
2022-06-06 00:26:08,580 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.0.attention.self.key.bias
2022-06-06 00:26:08,580 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.0.attention.self.key.weight
2022-06-06 00:26:08,580 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.0.attention.self.query.bias
2022-06-06 00:26:08,580 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.0.attention.self.query.weight
2022-06-06 00:26:08,580 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.0.attention.self.value.bias
2022-06-06 00:26:08,580 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.0.attention.self.value.weight
2022-06-06 00:26:08,580 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.0.intermediate.dense.bias
2022-06-06 00:26:08,580 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.0.intermediate.dense.weight
2022-06-06 00:26:08,580 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.0.output.LayerNorm.bias
2022-06-06 00:26:08,580 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.0.output.LayerNorm.weight
2022-06-06 00:26:08,580 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.0.output.dense.bias
2022-06-06 00:26:08,580 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.0.output.dense.weight
2022-06-06 00:26:08,580 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.1.attention.output.LayerNorm.bias
2022-06-06 00:26:08,580 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.1.attention.output.LayerNorm.weight
2022-06-06 00:26:08,580 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.1.attention.output.dense.bias
2022-06-06 00:26:08,581 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.1.attention.output.dense.weight
2022-06-06 00:26:08,581 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.1.attention.self.key.bias
2022-06-06 00:26:08,581 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.1.attention.self.key.weight
2022-06-06 00:26:08,581 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.1.attention.self.query.bias
2022-06-06 00:26:08,581 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.1.attention.self.query.weight
2022-06-06 00:26:08,581 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.1.attention.self.value.bias
2022-06-06 00:26:08,581 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.1.attention.self.value.weight
2022-06-06 00:26:08,581 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.1.intermediate.dense.bias
2022-06-06 00:26:08,581 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.1.intermediate.dense.weight
2022-06-06 00:26:08,581 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.1.output.LayerNorm.bias
2022-06-06 00:26:08,581 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.1.output.LayerNorm.weight
2022-06-06 00:26:08,581 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.1.output.dense.bias
2022-06-06 00:26:08,581 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.1.output.dense.weight
2022-06-06 00:26:08,581 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.10.attention.output.LayerNorm.bias
2022-06-06 00:26:08,582 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.10.attention.output.LayerNorm.weight
2022-06-06 00:26:08,582 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.10.attention.output.dense.bias
2022-06-06 00:26:08,582 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.10.attention.output.dense.weight
2022-06-06 00:26:08,582 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.10.attention.self.key.bias
2022-06-06 00:26:08,582 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.10.attention.self.key.weight
2022-06-06 00:26:08,582 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.10.attention.self.query.bias
2022-06-06 00:26:08,582 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.10.attention.self.query.weight
2022-06-06 00:26:08,582 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.10.attention.self.value.bias
2022-06-06 00:26:08,582 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.10.attention.self.value.weight
2022-06-06 00:26:08,582 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.10.intermediate.dense.bias
2022-06-06 00:26:08,582 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.10.intermediate.dense.weight
2022-06-06 00:26:08,582 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.10.output.LayerNorm.bias
2022-06-06 00:26:08,582 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.10.output.LayerNorm.weight
2022-06-06 00:26:08,582 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.10.output.dense.bias
2022-06-06 00:26:08,582 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.10.output.dense.weight
2022-06-06 00:26:08,583 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.11.attention.output.LayerNorm.bias
2022-06-06 00:26:08,583 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.11.attention.output.LayerNorm.weight
2022-06-06 00:26:08,583 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.11.attention.output.dense.bias
2022-06-06 00:26:08,583 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.11.attention.output.dense.weight
2022-06-06 00:26:08,583 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.11.attention.self.key.bias
2022-06-06 00:26:08,583 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.11.attention.self.key.weight
2022-06-06 00:26:08,583 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.11.attention.self.query.bias
2022-06-06 00:26:08,583 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.11.attention.self.query.weight
2022-06-06 00:26:08,583 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.11.attention.self.value.bias
2022-06-06 00:26:08,583 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.11.attention.self.value.weight
2022-06-06 00:26:08,583 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.11.intermediate.dense.bias
2022-06-06 00:26:08,583 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.11.intermediate.dense.weight
2022-06-06 00:26:08,583 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.11.output.LayerNorm.bias
2022-06-06 00:26:08,583 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.11.output.LayerNorm.weight
2022-06-06 00:26:08,584 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.11.output.dense.bias
2022-06-06 00:26:08,584 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.11.output.dense.weight
2022-06-06 00:26:08,584 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.2.attention.output.LayerNorm.bias
2022-06-06 00:26:08,584 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.2.attention.output.LayerNorm.weight
2022-06-06 00:26:08,584 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.2.attention.output.dense.bias
2022-06-06 00:26:08,584 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.2.attention.output.dense.weight
2022-06-06 00:26:08,584 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.2.attention.self.key.bias
2022-06-06 00:26:08,584 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.2.attention.self.key.weight
2022-06-06 00:26:08,584 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.2.attention.self.query.bias
2022-06-06 00:26:08,584 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.2.attention.self.query.weight
2022-06-06 00:26:08,584 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.2.attention.self.value.bias
2022-06-06 00:26:08,584 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.2.attention.self.value.weight
2022-06-06 00:26:08,584 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.2.intermediate.dense.bias
2022-06-06 00:26:08,584 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.2.intermediate.dense.weight
2022-06-06 00:26:08,584 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.2.output.LayerNorm.bias
2022-06-06 00:26:08,585 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.2.output.LayerNorm.weight
2022-06-06 00:26:08,585 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.2.output.dense.bias
2022-06-06 00:26:08,585 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.2.output.dense.weight
2022-06-06 00:26:08,585 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.3.attention.output.LayerNorm.bias
2022-06-06 00:26:08,585 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.3.attention.output.LayerNorm.weight
2022-06-06 00:26:08,585 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.3.attention.output.dense.bias
2022-06-06 00:26:08,585 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.3.attention.output.dense.weight
2022-06-06 00:26:08,585 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.3.attention.self.key.bias
2022-06-06 00:26:08,585 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.3.attention.self.key.weight
2022-06-06 00:26:08,585 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.3.attention.self.query.bias
2022-06-06 00:26:08,585 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.3.attention.self.query.weight
2022-06-06 00:26:08,585 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.3.attention.self.value.bias
2022-06-06 00:26:08,585 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.3.attention.self.value.weight
2022-06-06 00:26:08,585 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.3.intermediate.dense.bias
2022-06-06 00:26:08,585 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.3.intermediate.dense.weight
2022-06-06 00:26:08,586 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.3.output.LayerNorm.bias
2022-06-06 00:26:08,586 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.3.output.LayerNorm.weight
2022-06-06 00:26:08,586 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.3.output.dense.bias
2022-06-06 00:26:08,586 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.3.output.dense.weight
2022-06-06 00:26:08,586 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.4.attention.output.LayerNorm.bias
2022-06-06 00:26:08,586 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.4.attention.output.LayerNorm.weight
2022-06-06 00:26:08,586 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.4.attention.output.dense.bias
2022-06-06 00:26:08,586 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.4.attention.output.dense.weight
2022-06-06 00:26:08,586 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.4.attention.self.key.bias
2022-06-06 00:26:08,586 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.4.attention.self.key.weight
2022-06-06 00:26:08,586 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.4.attention.self.query.bias
2022-06-06 00:26:08,586 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.4.attention.self.query.weight
2022-06-06 00:26:08,586 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.4.attention.self.value.bias
2022-06-06 00:26:08,586 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.4.attention.self.value.weight
2022-06-06 00:26:08,587 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.4.intermediate.dense.bias
2022-06-06 00:26:08,587 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.4.intermediate.dense.weight
2022-06-06 00:26:08,587 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.4.output.LayerNorm.bias
2022-06-06 00:26:08,587 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.4.output.LayerNorm.weight
2022-06-06 00:26:08,587 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.4.output.dense.bias
2022-06-06 00:26:08,587 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.4.output.dense.weight
2022-06-06 00:26:08,587 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.5.attention.output.LayerNorm.bias
2022-06-06 00:26:08,587 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.5.attention.output.LayerNorm.weight
2022-06-06 00:26:08,587 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.5.attention.output.dense.bias
2022-06-06 00:26:08,587 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.5.attention.output.dense.weight
2022-06-06 00:26:08,587 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.5.attention.self.key.bias
2022-06-06 00:26:08,587 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.5.attention.self.key.weight
2022-06-06 00:26:08,587 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.5.attention.self.query.bias
2022-06-06 00:26:08,587 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.5.attention.self.query.weight
2022-06-06 00:26:08,587 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.5.attention.self.value.bias
2022-06-06 00:26:08,588 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.5.attention.self.value.weight
2022-06-06 00:26:08,588 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.5.intermediate.dense.bias
2022-06-06 00:26:08,588 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.5.intermediate.dense.weight
2022-06-06 00:26:08,588 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.5.output.LayerNorm.bias
2022-06-06 00:26:08,588 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.5.output.LayerNorm.weight
2022-06-06 00:26:08,588 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.5.output.dense.bias
2022-06-06 00:26:08,588 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.5.output.dense.weight
2022-06-06 00:26:08,588 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.6.attention.output.LayerNorm.bias
2022-06-06 00:26:08,588 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.6.attention.output.LayerNorm.weight
2022-06-06 00:26:08,588 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.6.attention.output.dense.bias
2022-06-06 00:26:08,588 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.6.attention.output.dense.weight
2022-06-06 00:26:08,588 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.6.attention.self.key.bias
2022-06-06 00:26:08,588 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.6.attention.self.key.weight
2022-06-06 00:26:08,588 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.6.attention.self.query.bias
2022-06-06 00:26:08,589 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.6.attention.self.query.weight
2022-06-06 00:26:08,589 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.6.attention.self.value.bias
2022-06-06 00:26:08,589 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.6.attention.self.value.weight
2022-06-06 00:26:08,589 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.6.intermediate.dense.bias
2022-06-06 00:26:08,589 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.6.intermediate.dense.weight
2022-06-06 00:26:08,589 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.6.output.LayerNorm.bias
2022-06-06 00:26:08,589 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.6.output.LayerNorm.weight
2022-06-06 00:26:08,589 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.6.output.dense.bias
2022-06-06 00:26:08,589 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.6.output.dense.weight
2022-06-06 00:26:08,589 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.7.attention.output.LayerNorm.bias
2022-06-06 00:26:08,589 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.7.attention.output.LayerNorm.weight
2022-06-06 00:26:08,589 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.7.attention.output.dense.bias
2022-06-06 00:26:08,589 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.7.attention.output.dense.weight
2022-06-06 00:26:08,589 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.7.attention.self.key.bias
2022-06-06 00:26:08,589 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.7.attention.self.key.weight
2022-06-06 00:26:08,590 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.7.attention.self.query.bias
2022-06-06 00:26:08,590 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.7.attention.self.query.weight
2022-06-06 00:26:08,590 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.7.attention.self.value.bias
2022-06-06 00:26:08,590 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.7.attention.self.value.weight
2022-06-06 00:26:08,590 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.7.intermediate.dense.bias
2022-06-06 00:26:08,590 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.7.intermediate.dense.weight
2022-06-06 00:26:08,590 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.7.output.LayerNorm.bias
2022-06-06 00:26:08,590 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.7.output.LayerNorm.weight
2022-06-06 00:26:08,590 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.7.output.dense.bias
2022-06-06 00:26:08,590 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.7.output.dense.weight
2022-06-06 00:26:08,590 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.8.attention.output.LayerNorm.bias
2022-06-06 00:26:08,590 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.8.attention.output.LayerNorm.weight
2022-06-06 00:26:08,590 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.8.attention.output.dense.bias
2022-06-06 00:26:08,590 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.8.attention.output.dense.weight
2022-06-06 00:26:08,590 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.8.attention.self.key.bias
2022-06-06 00:26:08,591 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.8.attention.self.key.weight
2022-06-06 00:26:08,591 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.8.attention.self.query.bias
2022-06-06 00:26:08,591 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.8.attention.self.query.weight
2022-06-06 00:26:08,591 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.8.attention.self.value.bias
2022-06-06 00:26:08,591 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.8.attention.self.value.weight
2022-06-06 00:26:08,591 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.8.intermediate.dense.bias
2022-06-06 00:26:08,591 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.8.intermediate.dense.weight
2022-06-06 00:26:08,591 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.8.output.LayerNorm.bias
2022-06-06 00:26:08,591 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.8.output.LayerNorm.weight
2022-06-06 00:26:08,591 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.8.output.dense.bias
2022-06-06 00:26:08,591 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.8.output.dense.weight
2022-06-06 00:26:08,591 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.9.attention.output.LayerNorm.bias
2022-06-06 00:26:08,591 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.9.attention.output.LayerNorm.weight
2022-06-06 00:26:08,591 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.9.attention.output.dense.bias
2022-06-06 00:26:08,591 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.9.attention.output.dense.weight
2022-06-06 00:26:08,592 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.9.attention.self.key.bias
2022-06-06 00:26:08,592 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.9.attention.self.key.weight
2022-06-06 00:26:08,592 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.9.attention.self.query.bias
2022-06-06 00:26:08,592 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.9.attention.self.query.weight
2022-06-06 00:26:08,592 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.9.attention.self.value.bias
2022-06-06 00:26:08,592 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.9.attention.self.value.weight
2022-06-06 00:26:08,592 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.9.intermediate.dense.bias
2022-06-06 00:26:08,592 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.9.intermediate.dense.weight
2022-06-06 00:26:08,592 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.9.output.LayerNorm.bias
2022-06-06 00:26:08,592 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.9.output.LayerNorm.weight
2022-06-06 00:26:08,592 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.9.output.dense.bias
2022-06-06 00:26:08,592 - INFO - allennlp.nn.initializers -    text_field_embedder.encoder.layer.9.output.dense.weight
2022-06-06 00:26:08,592 - INFO - allennlp.nn.initializers -    text_field_embedder.pooler.dense.bias
2022-06-06 00:26:08,592 - INFO - allennlp.nn.initializers -    text_field_embedder.pooler.dense.weight
2022-06-06 00:26:10,023 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 8, 'sorting_keys': [['quote_response', 'num_tokens']], 'type': 'bucket'} and extras {}
2022-06-06 00:26:10,023 - INFO - allennlp.common.params - iterator.type = bucket
2022-06-06 00:26:10,023 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 8, 'sorting_keys': [['quote_response', 'num_tokens']]} and extras {}
2022-06-06 00:26:10,024 - INFO - allennlp.common.params - iterator.sorting_keys = [['quote_response', 'num_tokens']]
2022-06-06 00:26:10,024 - INFO - allennlp.common.params - iterator.padding_noise = 0.1
2022-06-06 00:26:10,024 - INFO - allennlp.common.params - iterator.biggest_batch_first = False
2022-06-06 00:26:10,024 - INFO - allennlp.common.params - iterator.batch_size = 8
2022-06-06 00:26:10,024 - INFO - allennlp.common.params - iterator.instances_per_epoch = None
2022-06-06 00:26:10,024 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None
2022-06-06 00:26:10,025 - INFO - allennlp.common.params - iterator.cache_instances = False
2022-06-06 00:26:10,025 - INFO - allennlp.common.params - iterator.track_epoch = False
2022-06-06 00:26:10,025 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None
2022-06-06 00:26:10,025 - INFO - allennlp.common.params - validation_iterator = None
2022-06-06 00:26:10,025 - INFO - allennlp.common.params - trainer.no_grad = ()
2022-06-06 00:26:10,027 - INFO - my_library.training.transfer - Following parameters are Frozen  (without gradient):
2022-06-06 00:26:10,027 - INFO - my_library.training.transfer - Following parameters are Tunable (with gradient):
2022-06-06 00:26:10,027 - INFO - my_library.training.transfer - text_field_embedder.embeddings.word_embeddings.weight
2022-06-06 00:26:10,027 - INFO - my_library.training.transfer - text_field_embedder.embeddings.position_embeddings.weight
2022-06-06 00:26:10,027 - INFO - my_library.training.transfer - text_field_embedder.embeddings.token_type_embeddings.weight
2022-06-06 00:26:10,027 - INFO - my_library.training.transfer - text_field_embedder.embeddings.LayerNorm.weight
2022-06-06 00:26:10,028 - INFO - my_library.training.transfer - text_field_embedder.embeddings.LayerNorm.bias
2022-06-06 00:26:10,028 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.0.attention.self.query.weight
2022-06-06 00:26:10,028 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.0.attention.self.query.bias
2022-06-06 00:26:10,028 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.0.attention.self.key.weight
2022-06-06 00:26:10,028 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.0.attention.self.key.bias
2022-06-06 00:26:10,028 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.0.attention.self.value.weight
2022-06-06 00:26:10,028 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.0.attention.self.value.bias
2022-06-06 00:26:10,028 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.0.attention.output.dense.weight
2022-06-06 00:26:10,028 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.0.attention.output.dense.bias
2022-06-06 00:26:10,029 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.0.attention.output.LayerNorm.weight
2022-06-06 00:26:10,029 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.0.attention.output.LayerNorm.bias
2022-06-06 00:26:10,029 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.0.intermediate.dense.weight
2022-06-06 00:26:10,029 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.0.intermediate.dense.bias
2022-06-06 00:26:10,029 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.0.output.dense.weight
2022-06-06 00:26:10,029 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.0.output.dense.bias
2022-06-06 00:26:10,029 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.0.output.LayerNorm.weight
2022-06-06 00:26:10,029 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.0.output.LayerNorm.bias
2022-06-06 00:26:10,029 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.1.attention.self.query.weight
2022-06-06 00:26:10,030 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.1.attention.self.query.bias
2022-06-06 00:26:10,030 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.1.attention.self.key.weight
2022-06-06 00:26:10,030 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.1.attention.self.key.bias
2022-06-06 00:26:10,030 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.1.attention.self.value.weight
2022-06-06 00:26:10,030 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.1.attention.self.value.bias
2022-06-06 00:26:10,030 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.1.attention.output.dense.weight
2022-06-06 00:26:10,030 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.1.attention.output.dense.bias
2022-06-06 00:26:10,030 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.1.attention.output.LayerNorm.weight
2022-06-06 00:26:10,030 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.1.attention.output.LayerNorm.bias
2022-06-06 00:26:10,031 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.1.intermediate.dense.weight
2022-06-06 00:26:10,031 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.1.intermediate.dense.bias
2022-06-06 00:26:10,031 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.1.output.dense.weight
2022-06-06 00:26:10,031 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.1.output.dense.bias
2022-06-06 00:26:10,031 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.1.output.LayerNorm.weight
2022-06-06 00:26:10,031 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.1.output.LayerNorm.bias
2022-06-06 00:26:10,031 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.2.attention.self.query.weight
2022-06-06 00:26:10,031 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.2.attention.self.query.bias
2022-06-06 00:26:10,031 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.2.attention.self.key.weight
2022-06-06 00:26:10,032 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.2.attention.self.key.bias
2022-06-06 00:26:10,032 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.2.attention.self.value.weight
2022-06-06 00:26:10,032 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.2.attention.self.value.bias
2022-06-06 00:26:10,032 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.2.attention.output.dense.weight
2022-06-06 00:26:10,032 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.2.attention.output.dense.bias
2022-06-06 00:26:10,032 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.2.attention.output.LayerNorm.weight
2022-06-06 00:26:10,032 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.2.attention.output.LayerNorm.bias
2022-06-06 00:26:10,032 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.2.intermediate.dense.weight
2022-06-06 00:26:10,032 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.2.intermediate.dense.bias
2022-06-06 00:26:10,033 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.2.output.dense.weight
2022-06-06 00:26:10,033 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.2.output.dense.bias
2022-06-06 00:26:10,033 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.2.output.LayerNorm.weight
2022-06-06 00:26:10,033 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.2.output.LayerNorm.bias
2022-06-06 00:26:10,033 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.3.attention.self.query.weight
2022-06-06 00:26:10,033 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.3.attention.self.query.bias
2022-06-06 00:26:10,033 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.3.attention.self.key.weight
2022-06-06 00:26:10,033 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.3.attention.self.key.bias
2022-06-06 00:26:10,033 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.3.attention.self.value.weight
2022-06-06 00:26:10,034 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.3.attention.self.value.bias
2022-06-06 00:26:10,034 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.3.attention.output.dense.weight
2022-06-06 00:26:10,034 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.3.attention.output.dense.bias
2022-06-06 00:26:10,034 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.3.attention.output.LayerNorm.weight
2022-06-06 00:26:10,034 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.3.attention.output.LayerNorm.bias
2022-06-06 00:26:10,034 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.3.intermediate.dense.weight
2022-06-06 00:26:10,034 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.3.intermediate.dense.bias
2022-06-06 00:26:10,034 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.3.output.dense.weight
2022-06-06 00:26:10,034 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.3.output.dense.bias
2022-06-06 00:26:10,035 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.3.output.LayerNorm.weight
2022-06-06 00:26:10,035 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.3.output.LayerNorm.bias
2022-06-06 00:26:10,035 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.4.attention.self.query.weight
2022-06-06 00:26:10,035 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.4.attention.self.query.bias
2022-06-06 00:26:10,035 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.4.attention.self.key.weight
2022-06-06 00:26:10,035 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.4.attention.self.key.bias
2022-06-06 00:26:10,035 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.4.attention.self.value.weight
2022-06-06 00:26:10,035 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.4.attention.self.value.bias
2022-06-06 00:26:10,035 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.4.attention.output.dense.weight
2022-06-06 00:26:10,036 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.4.attention.output.dense.bias
2022-06-06 00:26:10,036 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.4.attention.output.LayerNorm.weight
2022-06-06 00:26:10,036 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.4.attention.output.LayerNorm.bias
2022-06-06 00:26:10,036 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.4.intermediate.dense.weight
2022-06-06 00:26:10,036 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.4.intermediate.dense.bias
2022-06-06 00:26:10,036 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.4.output.dense.weight
2022-06-06 00:26:10,036 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.4.output.dense.bias
2022-06-06 00:26:10,036 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.4.output.LayerNorm.weight
2022-06-06 00:26:10,036 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.4.output.LayerNorm.bias
2022-06-06 00:26:10,037 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.5.attention.self.query.weight
2022-06-06 00:26:10,037 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.5.attention.self.query.bias
2022-06-06 00:26:10,037 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.5.attention.self.key.weight
2022-06-06 00:26:10,037 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.5.attention.self.key.bias
2022-06-06 00:26:10,037 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.5.attention.self.value.weight
2022-06-06 00:26:10,037 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.5.attention.self.value.bias
2022-06-06 00:26:10,037 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.5.attention.output.dense.weight
2022-06-06 00:26:10,037 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.5.attention.output.dense.bias
2022-06-06 00:26:10,037 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.5.attention.output.LayerNorm.weight
2022-06-06 00:26:10,038 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.5.attention.output.LayerNorm.bias
2022-06-06 00:26:10,038 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.5.intermediate.dense.weight
2022-06-06 00:26:10,038 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.5.intermediate.dense.bias
2022-06-06 00:26:10,038 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.5.output.dense.weight
2022-06-06 00:26:10,038 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.5.output.dense.bias
2022-06-06 00:26:10,038 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.5.output.LayerNorm.weight
2022-06-06 00:26:10,038 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.5.output.LayerNorm.bias
2022-06-06 00:26:10,038 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.6.attention.self.query.weight
2022-06-06 00:26:10,038 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.6.attention.self.query.bias
2022-06-06 00:26:10,039 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.6.attention.self.key.weight
2022-06-06 00:26:10,039 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.6.attention.self.key.bias
2022-06-06 00:26:10,039 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.6.attention.self.value.weight
2022-06-06 00:26:10,039 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.6.attention.self.value.bias
2022-06-06 00:26:10,039 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.6.attention.output.dense.weight
2022-06-06 00:26:10,039 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.6.attention.output.dense.bias
2022-06-06 00:26:10,039 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.6.attention.output.LayerNorm.weight
2022-06-06 00:26:10,039 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.6.attention.output.LayerNorm.bias
2022-06-06 00:26:10,039 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.6.intermediate.dense.weight
2022-06-06 00:26:10,040 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.6.intermediate.dense.bias
2022-06-06 00:26:10,040 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.6.output.dense.weight
2022-06-06 00:26:10,040 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.6.output.dense.bias
2022-06-06 00:26:10,040 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.6.output.LayerNorm.weight
2022-06-06 00:26:10,040 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.6.output.LayerNorm.bias
2022-06-06 00:26:10,040 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.7.attention.self.query.weight
2022-06-06 00:26:10,040 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.7.attention.self.query.bias
2022-06-06 00:26:10,040 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.7.attention.self.key.weight
2022-06-06 00:26:10,040 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.7.attention.self.key.bias
2022-06-06 00:26:10,041 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.7.attention.self.value.weight
2022-06-06 00:26:10,041 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.7.attention.self.value.bias
2022-06-06 00:26:10,041 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.7.attention.output.dense.weight
2022-06-06 00:26:10,041 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.7.attention.output.dense.bias
2022-06-06 00:26:10,041 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.7.attention.output.LayerNorm.weight
2022-06-06 00:26:10,041 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.7.attention.output.LayerNorm.bias
2022-06-06 00:26:10,041 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.7.intermediate.dense.weight
2022-06-06 00:26:10,041 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.7.intermediate.dense.bias
2022-06-06 00:26:10,041 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.7.output.dense.weight
2022-06-06 00:26:10,042 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.7.output.dense.bias
2022-06-06 00:26:10,042 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.7.output.LayerNorm.weight
2022-06-06 00:26:10,042 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.7.output.LayerNorm.bias
2022-06-06 00:26:10,042 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.8.attention.self.query.weight
2022-06-06 00:26:10,042 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.8.attention.self.query.bias
2022-06-06 00:26:10,042 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.8.attention.self.key.weight
2022-06-06 00:26:10,042 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.8.attention.self.key.bias
2022-06-06 00:26:10,042 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.8.attention.self.value.weight
2022-06-06 00:26:10,042 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.8.attention.self.value.bias
2022-06-06 00:26:10,042 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.8.attention.output.dense.weight
2022-06-06 00:26:10,042 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.8.attention.output.dense.bias
2022-06-06 00:26:10,042 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.8.attention.output.LayerNorm.weight
2022-06-06 00:26:10,042 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.8.attention.output.LayerNorm.bias
2022-06-06 00:26:10,042 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.8.intermediate.dense.weight
2022-06-06 00:26:10,043 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.8.intermediate.dense.bias
2022-06-06 00:26:10,043 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.8.output.dense.weight
2022-06-06 00:26:10,043 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.8.output.dense.bias
2022-06-06 00:26:10,043 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.8.output.LayerNorm.weight
2022-06-06 00:26:10,043 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.8.output.LayerNorm.bias
2022-06-06 00:26:10,043 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.9.attention.self.query.weight
2022-06-06 00:26:10,043 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.9.attention.self.query.bias
2022-06-06 00:26:10,043 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.9.attention.self.key.weight
2022-06-06 00:26:10,043 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.9.attention.self.key.bias
2022-06-06 00:26:10,043 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.9.attention.self.value.weight
2022-06-06 00:26:10,043 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.9.attention.self.value.bias
2022-06-06 00:26:10,043 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.9.attention.output.dense.weight
2022-06-06 00:26:10,043 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.9.attention.output.dense.bias
2022-06-06 00:26:10,043 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.9.attention.output.LayerNorm.weight
2022-06-06 00:26:10,043 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.9.attention.output.LayerNorm.bias
2022-06-06 00:26:10,044 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.9.intermediate.dense.weight
2022-06-06 00:26:10,044 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.9.intermediate.dense.bias
2022-06-06 00:26:10,044 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.9.output.dense.weight
2022-06-06 00:26:10,044 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.9.output.dense.bias
2022-06-06 00:26:10,044 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.9.output.LayerNorm.weight
2022-06-06 00:26:10,044 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.9.output.LayerNorm.bias
2022-06-06 00:26:10,044 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.10.attention.self.query.weight
2022-06-06 00:26:10,044 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.10.attention.self.query.bias
2022-06-06 00:26:10,044 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.10.attention.self.key.weight
2022-06-06 00:26:10,044 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.10.attention.self.key.bias
2022-06-06 00:26:10,044 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.10.attention.self.value.weight
2022-06-06 00:26:10,044 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.10.attention.self.value.bias
2022-06-06 00:26:10,044 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.10.attention.output.dense.weight
2022-06-06 00:26:10,044 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.10.attention.output.dense.bias
2022-06-06 00:26:10,044 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.10.attention.output.LayerNorm.weight
2022-06-06 00:26:10,045 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.10.attention.output.LayerNorm.bias
2022-06-06 00:26:10,045 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.10.intermediate.dense.weight
2022-06-06 00:26:10,045 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.10.intermediate.dense.bias
2022-06-06 00:26:10,045 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.10.output.dense.weight
2022-06-06 00:26:10,045 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.10.output.dense.bias
2022-06-06 00:26:10,045 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.10.output.LayerNorm.weight
2022-06-06 00:26:10,045 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.10.output.LayerNorm.bias
2022-06-06 00:26:10,045 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.11.attention.self.query.weight
2022-06-06 00:26:10,045 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.11.attention.self.query.bias
2022-06-06 00:26:10,045 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.11.attention.self.key.weight
2022-06-06 00:26:10,045 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.11.attention.self.key.bias
2022-06-06 00:26:10,045 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.11.attention.self.value.weight
2022-06-06 00:26:10,045 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.11.attention.self.value.bias
2022-06-06 00:26:10,045 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.11.attention.output.dense.weight
2022-06-06 00:26:10,045 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.11.attention.output.dense.bias
2022-06-06 00:26:10,045 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.11.attention.output.LayerNorm.weight
2022-06-06 00:26:10,046 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.11.attention.output.LayerNorm.bias
2022-06-06 00:26:10,046 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.11.intermediate.dense.weight
2022-06-06 00:26:10,046 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.11.intermediate.dense.bias
2022-06-06 00:26:10,046 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.11.output.dense.weight
2022-06-06 00:26:10,046 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.11.output.dense.bias
2022-06-06 00:26:10,046 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.11.output.LayerNorm.weight
2022-06-06 00:26:10,046 - INFO - my_library.training.transfer - text_field_embedder.encoder.layer.11.output.LayerNorm.bias
2022-06-06 00:26:10,046 - INFO - my_library.training.transfer - text_field_embedder.pooler.dense.weight
2022-06-06 00:26:10,046 - INFO - my_library.training.transfer - text_field_embedder.pooler.dense.bias
2022-06-06 00:26:10,046 - INFO - my_library.training.transfer - linear.weight
2022-06-06 00:26:10,046 - INFO - my_library.training.transfer - linear.bias
2022-06-06 00:26:10,046 - INFO - allennlp.common.params - trainer.type = default
2022-06-06 00:26:10,046 - INFO - allennlp.common.params - trainer.patience = 3
2022-06-06 00:26:10,046 - INFO - allennlp.common.params - trainer.validation_metric = +average_F1
2022-06-06 00:26:10,047 - INFO - allennlp.common.params - trainer.shuffle = True
2022-06-06 00:26:10,047 - INFO - allennlp.common.params - trainer.num_epochs = 30
2022-06-06 00:26:10,047 - INFO - allennlp.common.params - trainer.cuda_device = 0
2022-06-06 00:26:10,047 - INFO - allennlp.common.params - trainer.grad_norm = None
2022-06-06 00:26:10,047 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-06-06 00:26:10,047 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2022-06-06 00:26:14,110 - INFO - allennlp.common.params - trainer.optimizer.type = adagrad
2022-06-06 00:26:14,110 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None
2022-06-06 00:26:14,110 - INFO - allennlp.training.optimizers - Number of trainable parameters: 109483778
2022-06-06 00:26:14,111 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
2022-06-06 00:26:14,111 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: 
2022-06-06 00:26:14,112 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.0001
2022-06-06 00:26:14,120 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 20
2022-06-06 00:26:14,120 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None
2022-06-06 00:26:14,120 - INFO - allennlp.common.params - trainer.model_save_interval = None
2022-06-06 00:26:14,121 - INFO - allennlp.common.params - trainer.summary_interval = 100
2022-06-06 00:26:14,121 - INFO - allennlp.common.params - trainer.histogram_interval = None
2022-06-06 00:26:14,121 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True
2022-06-06 00:26:14,121 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False
2022-06-06 00:26:14,121 - INFO - allennlp.common.params - trainer.log_batch_size_period = None
2022-06-06 00:26:14,124 - INFO - allennlp.common.params - evaluate_on_test = True
2022-06-06 00:26:14,124 - INFO - allennlp.training.trainer - Beginning training.
2022-06-06 00:26:14,125 - INFO - allennlp.training.trainer - Epoch 0/29
2022-06-06 00:26:14,125 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4507.912
2022-06-06 00:26:14,210 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 6708
2022-06-06 00:26:14,212 - INFO - allennlp.training.trainer - Training
2022-06-06 00:26:19,187 - INFO - allennlp.training.trainer - Validating
2022-06-06 00:26:19,584 - INFO - allennlp.training.trainer -                     Training |  Validation
2022-06-06 00:26:19,584 - INFO - allennlp.training.trainer - Yes_F1          |     0.668  |     0.738
2022-06-06 00:26:19,585 - INFO - allennlp.training.trainer - loss            |     0.602  |     0.390
2022-06-06 00:26:19,585 - INFO - allennlp.training.trainer - No_F1           |     0.820  |     0.829
2022-06-06 00:26:19,585 - INFO - allennlp.training.trainer - gpu_0_memory_MB |  6708.000  |       N/A
2022-06-06 00:26:19,585 - INFO - allennlp.training.trainer - No_R            |     0.821  |     0.776
2022-06-06 00:26:19,585 - INFO - allennlp.training.trainer - accuracy        |     0.767  |     0.793
2022-06-06 00:26:19,585 - INFO - allennlp.training.trainer - cpu_memory_MB   |  4507.912  |       N/A
2022-06-06 00:26:19,585 - INFO - allennlp.training.trainer - Yes_P           |     0.669  |     0.667
2022-06-06 00:26:19,585 - INFO - allennlp.training.trainer - No_P            |     0.819  |     0.891
2022-06-06 00:26:19,585 - INFO - allennlp.training.trainer - average_F1      |     0.744  |     0.784
2022-06-06 00:26:19,585 - INFO - allennlp.training.trainer - Yes_R           |     0.667  |     0.825
2022-06-06 00:26:21,152 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to 'ColbertTwitterFine/best.th'.
2022-06-06 00:26:21,669 - INFO - allennlp.training.trainer - Epoch duration: 00:00:07
2022-06-06 00:26:21,670 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:38
2022-06-06 00:26:21,670 - INFO - allennlp.training.trainer - Epoch 1/29
2022-06-06 00:26:21,670 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4507.912
2022-06-06 00:26:21,750 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 8664
2022-06-06 00:26:21,751 - INFO - allennlp.training.trainer - Training
2022-06-06 00:26:26,702 - INFO - allennlp.training.trainer - Validating
2022-06-06 00:26:27,086 - INFO - allennlp.training.trainer -                     Training |  Validation
2022-06-06 00:26:27,087 - INFO - allennlp.training.trainer - Yes_F1          |     0.927  |     0.787
2022-06-06 00:26:27,087 - INFO - allennlp.training.trainer - loss            |     0.156  |     0.365
2022-06-06 00:26:27,087 - INFO - allennlp.training.trainer - No_F1           |     0.958  |     0.890
2022-06-06 00:26:27,087 - INFO - allennlp.training.trainer - gpu_0_memory_MB |  8664.000  |       N/A
2022-06-06 00:26:27,087 - INFO - allennlp.training.trainer - No_R            |     0.942  |     0.905
2022-06-06 00:26:27,087 - INFO - allennlp.training.trainer - accuracy        |     0.947  |     0.855
2022-06-06 00:26:27,087 - INFO - allennlp.training.trainer - cpu_memory_MB   |  4507.912  |       N/A
2022-06-06 00:26:27,087 - INFO - allennlp.training.trainer - Yes_P           |     0.899  |     0.814
2022-06-06 00:26:27,088 - INFO - allennlp.training.trainer - No_P            |     0.975  |     0.875
2022-06-06 00:26:27,088 - INFO - allennlp.training.trainer - average_F1      |     0.943  |     0.838
2022-06-06 00:26:27,088 - INFO - allennlp.training.trainer - Yes_R           |     0.956  |     0.762
2022-06-06 00:26:28,601 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to 'ColbertTwitterFine/best.th'.
2022-06-06 00:26:33,169 - INFO - allennlp.training.trainer - Epoch duration: 00:00:11
2022-06-06 00:26:33,169 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:04:26
2022-06-06 00:26:33,169 - INFO - allennlp.training.trainer - Epoch 2/29
2022-06-06 00:26:33,169 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4507.912
2022-06-06 00:26:33,245 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4269
2022-06-06 00:26:33,247 - INFO - allennlp.training.trainer - Training
2022-06-06 00:26:38,174 - INFO - allennlp.training.trainer - Validating
2022-06-06 00:26:38,543 - INFO - allennlp.training.trainer -                     Training |  Validation
2022-06-06 00:26:38,543 - INFO - allennlp.training.trainer - Yes_F1          |     0.978  |     0.793
2022-06-06 00:26:38,544 - INFO - allennlp.training.trainer - loss            |     0.054  |     0.421
2022-06-06 00:26:38,544 - INFO - allennlp.training.trainer - No_F1           |     0.988  |     0.895
2022-06-06 00:26:38,544 - INFO - allennlp.training.trainer - gpu_0_memory_MB |  4269.000  |       N/A
2022-06-06 00:26:38,544 - INFO - allennlp.training.trainer - No_R            |     0.983  |     0.914
2022-06-06 00:26:38,544 - INFO - allennlp.training.trainer - accuracy        |     0.985  |     0.860
2022-06-06 00:26:38,544 - INFO - allennlp.training.trainer - cpu_memory_MB   |  4507.912  |       N/A
2022-06-06 00:26:38,544 - INFO - allennlp.training.trainer - Yes_P           |     0.969  |     0.828
2022-06-06 00:26:38,544 - INFO - allennlp.training.trainer - No_P            |     0.993  |     0.876
2022-06-06 00:26:38,545 - INFO - allennlp.training.trainer - average_F1      |     0.983  |     0.844
2022-06-06 00:26:38,545 - INFO - allennlp.training.trainer - Yes_R           |     0.988  |     0.762
2022-06-06 00:26:40,024 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to 'ColbertTwitterFine/best.th'.
2022-06-06 00:26:41,565 - INFO - allennlp.training.trainer - Epoch duration: 00:00:08
2022-06-06 00:26:41,565 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:04:06
2022-06-06 00:26:41,565 - INFO - allennlp.training.trainer - Epoch 3/29
2022-06-06 00:26:41,565 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4507.912
2022-06-06 00:26:41,642 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4269
2022-06-06 00:26:41,643 - INFO - allennlp.training.trainer - Training
2022-06-06 00:26:46,552 - INFO - allennlp.training.trainer - Validating
2022-06-06 00:26:46,920 - INFO - allennlp.training.trainer -                     Training |  Validation
2022-06-06 00:26:46,920 - INFO - allennlp.training.trainer - Yes_F1          |     0.994  |     0.803
2022-06-06 00:26:46,921 - INFO - allennlp.training.trainer - loss            |     0.019  |     0.451
2022-06-06 00:26:46,921 - INFO - allennlp.training.trainer - No_F1           |     0.997  |     0.905
2022-06-06 00:26:46,921 - INFO - allennlp.training.trainer - gpu_0_memory_MB |  4269.000  |       N/A
2022-06-06 00:26:46,921 - INFO - allennlp.training.trainer - No_R            |     0.994  |     0.940
2022-06-06 00:26:46,921 - INFO - allennlp.training.trainer - accuracy        |     0.996  |     0.872
2022-06-06 00:26:46,921 - INFO - allennlp.training.trainer - cpu_memory_MB   |  4507.912  |       N/A
2022-06-06 00:26:46,921 - INFO - allennlp.training.trainer - Yes_P           |     0.988  |     0.870
2022-06-06 00:26:46,921 - INFO - allennlp.training.trainer - No_P            |     1.000  |     0.872
2022-06-06 00:26:46,922 - INFO - allennlp.training.trainer - average_F1      |     0.995  |     0.854
2022-06-06 00:26:46,922 - INFO - allennlp.training.trainer - Yes_R           |     1.000  |     0.746
2022-06-06 00:26:48,403 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to 'ColbertTwitterFine/best.th'.
2022-06-06 00:26:49,995 - INFO - allennlp.training.trainer - Epoch duration: 00:00:08
2022-06-06 00:26:49,995 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:53
2022-06-06 00:26:49,995 - INFO - allennlp.training.trainer - Epoch 4/29
2022-06-06 00:26:49,995 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4507.912
2022-06-06 00:26:50,072 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4397
2022-06-06 00:26:50,074 - INFO - allennlp.training.trainer - Training
2022-06-06 00:26:54,998 - INFO - allennlp.training.trainer - Validating
2022-06-06 00:26:55,364 - INFO - allennlp.training.trainer -                     Training |  Validation
2022-06-06 00:26:55,364 - INFO - allennlp.training.trainer - Yes_F1          |     0.998  |     0.796
2022-06-06 00:26:55,364 - INFO - allennlp.training.trainer - loss            |     0.010  |     0.509
2022-06-06 00:26:55,364 - INFO - allennlp.training.trainer - No_F1           |     0.999  |     0.906
2022-06-06 00:26:55,365 - INFO - allennlp.training.trainer - gpu_0_memory_MB |  4397.000  |       N/A
2022-06-06 00:26:55,365 - INFO - allennlp.training.trainer - No_R            |     0.998  |     0.957
2022-06-06 00:26:55,365 - INFO - allennlp.training.trainer - accuracy        |     0.999  |     0.872
2022-06-06 00:26:55,365 - INFO - allennlp.training.trainer - cpu_memory_MB   |  4507.912  |       N/A
2022-06-06 00:26:55,365 - INFO - allennlp.training.trainer - Yes_P           |     0.996  |     0.900
2022-06-06 00:26:55,365 - INFO - allennlp.training.trainer - No_P            |     1.000  |     0.860
2022-06-06 00:26:55,365 - INFO - allennlp.training.trainer - average_F1      |     0.998  |     0.851
2022-06-06 00:26:55,365 - INFO - allennlp.training.trainer - Yes_R           |     1.000  |     0.714
2022-06-06 00:26:56,841 - INFO - allennlp.training.trainer - Epoch duration: 00:00:06
2022-06-06 00:26:56,842 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:33
2022-06-06 00:26:56,842 - INFO - allennlp.training.trainer - Epoch 5/29
2022-06-06 00:26:56,842 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4507.912
2022-06-06 00:26:56,918 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4397
2022-06-06 00:26:56,920 - INFO - allennlp.training.trainer - Training
2022-06-06 00:27:01,866 - INFO - allennlp.training.trainer - Validating
2022-06-06 00:27:02,238 - INFO - allennlp.training.trainer -                     Training |  Validation
2022-06-06 00:27:02,238 - INFO - allennlp.training.trainer - Yes_F1          |     0.998  |     0.824
2022-06-06 00:27:02,238 - INFO - allennlp.training.trainer - loss            |     0.007  |     0.457
2022-06-06 00:27:02,238 - INFO - allennlp.training.trainer - No_F1           |     0.999  |     0.912
2022-06-06 00:27:02,238 - INFO - allennlp.training.trainer - gpu_0_memory_MB |  4397.000  |       N/A
2022-06-06 00:27:02,238 - INFO - allennlp.training.trainer - No_R            |     0.998  |     0.940
2022-06-06 00:27:02,239 - INFO - allennlp.training.trainer - accuracy        |     0.999  |     0.883
2022-06-06 00:27:02,239 - INFO - allennlp.training.trainer - cpu_memory_MB   |  4507.912  |       N/A
2022-06-06 00:27:02,239 - INFO - allennlp.training.trainer - Yes_P           |     0.996  |     0.875
2022-06-06 00:27:02,239 - INFO - allennlp.training.trainer - No_P            |     1.000  |     0.886
2022-06-06 00:27:02,239 - INFO - allennlp.training.trainer - average_F1      |     0.998  |     0.868
2022-06-06 00:27:02,239 - INFO - allennlp.training.trainer - Yes_R           |     1.000  |     0.778
2022-06-06 00:27:03,716 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to 'ColbertTwitterFine/best.th'.
2022-06-06 00:27:05,226 - INFO - allennlp.training.trainer - Epoch duration: 00:00:08
2022-06-06 00:27:05,226 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:24
2022-06-06 00:27:05,226 - INFO - allennlp.training.trainer - Epoch 6/29
2022-06-06 00:27:05,226 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4507.912
2022-06-06 00:27:05,302 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4397
2022-06-06 00:27:05,304 - INFO - allennlp.training.trainer - Training
2022-06-06 00:27:10,095 - INFO - allennlp.training.trainer - Validating
2022-06-06 00:27:10,441 - INFO - allennlp.training.trainer -                     Training |  Validation
2022-06-06 00:27:10,441 - INFO - allennlp.training.trainer - Yes_F1          |     0.998  |     0.833
2022-06-06 00:27:10,441 - INFO - allennlp.training.trainer - loss            |     0.004  |     0.459
2022-06-06 00:27:10,442 - INFO - allennlp.training.trainer - No_F1           |     0.999  |     0.916
2022-06-06 00:27:10,442 - INFO - allennlp.training.trainer - gpu_0_memory_MB |  4397.000  |       N/A
2022-06-06 00:27:10,442 - INFO - allennlp.training.trainer - No_R            |     0.998  |     0.940
2022-06-06 00:27:10,442 - INFO - allennlp.training.trainer - accuracy        |     0.999  |     0.888
2022-06-06 00:27:10,442 - INFO - allennlp.training.trainer - cpu_memory_MB   |  4507.912  |       N/A
2022-06-06 00:27:10,442 - INFO - allennlp.training.trainer - Yes_P           |     0.996  |     0.877
2022-06-06 00:27:10,442 - INFO - allennlp.training.trainer - No_P            |     1.000  |     0.893
2022-06-06 00:27:10,442 - INFO - allennlp.training.trainer - average_F1      |     0.998  |     0.875
2022-06-06 00:27:10,442 - INFO - allennlp.training.trainer - Yes_R           |     1.000  |     0.794
2022-06-06 00:27:11,889 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to 'ColbertTwitterFine/best.th'.
2022-06-06 00:27:15,525 - INFO - allennlp.training.trainer - Epoch duration: 00:00:10
2022-06-06 00:27:15,525 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:21
2022-06-06 00:27:15,525 - INFO - allennlp.training.trainer - Epoch 7/29
2022-06-06 00:27:15,525 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4507.912
2022-06-06 00:27:15,603 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4397
2022-06-06 00:27:15,604 - INFO - allennlp.training.trainer - Training
2022-06-06 00:27:20,511 - INFO - allennlp.training.trainer - Validating
2022-06-06 00:27:20,870 - INFO - allennlp.training.trainer -                     Training |  Validation
2022-06-06 00:27:20,870 - INFO - allennlp.training.trainer - Yes_F1          |     1.000  |     0.824
2022-06-06 00:27:20,871 - INFO - allennlp.training.trainer - loss            |     0.003  |     0.485
2022-06-06 00:27:20,871 - INFO - allennlp.training.trainer - No_F1           |     1.000  |     0.912
2022-06-06 00:27:20,871 - INFO - allennlp.training.trainer - gpu_0_memory_MB |  4397.000  |       N/A
2022-06-06 00:27:20,871 - INFO - allennlp.training.trainer - No_R            |     1.000  |     0.940
2022-06-06 00:27:20,871 - INFO - allennlp.training.trainer - accuracy        |     1.000  |     0.883
2022-06-06 00:27:20,871 - INFO - allennlp.training.trainer - cpu_memory_MB   |  4507.912  |       N/A
2022-06-06 00:27:20,871 - INFO - allennlp.training.trainer - Yes_P           |     1.000  |     0.875
2022-06-06 00:27:20,871 - INFO - allennlp.training.trainer - No_P            |     1.000  |     0.886
2022-06-06 00:27:20,871 - INFO - allennlp.training.trainer - average_F1      |     1.000  |     0.868
2022-06-06 00:27:20,872 - INFO - allennlp.training.trainer - Yes_R           |     1.000  |     0.778
2022-06-06 00:27:22,322 - INFO - allennlp.training.trainer - Epoch duration: 00:00:06
2022-06-06 00:27:22,323 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:07
2022-06-06 00:27:22,323 - INFO - allennlp.training.trainer - Epoch 8/29
2022-06-06 00:27:22,323 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4507.912
2022-06-06 00:27:22,399 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4397
2022-06-06 00:27:22,400 - INFO - allennlp.training.trainer - Training
2022-06-06 00:27:27,208 - INFO - allennlp.training.trainer - Validating
2022-06-06 00:27:27,573 - INFO - allennlp.training.trainer -                     Training |  Validation
2022-06-06 00:27:27,573 - INFO - allennlp.training.trainer - Yes_F1          |     1.000  |     0.817
2022-06-06 00:27:27,573 - INFO - allennlp.training.trainer - loss            |     0.002  |     0.479
2022-06-06 00:27:27,573 - INFO - allennlp.training.trainer - No_F1           |     1.000  |     0.908
2022-06-06 00:27:27,573 - INFO - allennlp.training.trainer - gpu_0_memory_MB |  4397.000  |       N/A
2022-06-06 00:27:27,573 - INFO - allennlp.training.trainer - No_R            |     1.000  |     0.931
2022-06-06 00:27:27,574 - INFO - allennlp.training.trainer - accuracy        |     1.000  |     0.877
2022-06-06 00:27:27,574 - INFO - allennlp.training.trainer - cpu_memory_MB   |  4507.912  |       N/A
2022-06-06 00:27:27,574 - INFO - allennlp.training.trainer - Yes_P           |     1.000  |     0.860
2022-06-06 00:27:27,574 - INFO - allennlp.training.trainer - No_P            |     1.000  |     0.885
2022-06-06 00:27:27,574 - INFO - allennlp.training.trainer - average_F1      |     1.000  |     0.862
2022-06-06 00:27:27,574 - INFO - allennlp.training.trainer - Yes_R           |     1.000  |     0.778
2022-06-06 00:27:29,060 - INFO - allennlp.training.trainer - Epoch duration: 00:00:06
2022-06-06 00:27:29,060 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:54
2022-06-06 00:27:29,060 - INFO - allennlp.training.trainer - Epoch 9/29
2022-06-06 00:27:29,060 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4507.912
2022-06-06 00:27:29,137 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4397
2022-06-06 00:27:29,139 - INFO - allennlp.training.trainer - Training
2022-06-06 00:27:33,930 - INFO - allennlp.training.trainer - Validating
2022-06-06 00:27:34,274 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2022-06-06 00:27:34,274 - INFO - allennlp.models.archival - archiving weights and vocabulary to ColbertTwitterFine/model.tar.gz
2022-06-06 00:27:57,185 - INFO - my_library.training.transfer - Loading the best epoch weights.
2022-06-06 00:27:57,399 - INFO - my_library.training.transfer - The model will be evaluated using the best epoch weights.
2022-06-06 00:27:57,400 - INFO - allennlp.commands.evaluate - Iterating over dataset
2022-06-06 00:27:57,602 - INFO - allennlp.common.util - Metrics: {
  "peak_cpu_memory_MB": 4507.912,
  "peak_gpu_0_memory_MB": 8664,
  "training_duration": "00:01:13",
  "training_start_epoch": 0,
  "training_epochs": 8,
  "epoch": 8,
  "training_No_P": 1.0,
  "training_No_R": 1.0,
  "training_No_F1": 0.99999999999995,
  "training_Yes_P": 1.0,
  "training_Yes_R": 1.0,
  "training_Yes_F1": 0.99999999999995,
  "training_accuracy": 1.0,
  "training_average_F1": 0.99999999999995,
  "training_loss": 0.0022592594106148074,
  "training_cpu_memory_MB": 4507.912,
  "training_gpu_0_memory_MB": 4397,
  "validation_No_P": 0.8852459016393442,
  "validation_No_R": 0.9310344827586207,
  "validation_No_F1": 0.9075630252100341,
  "validation_Yes_P": 0.8596491228070176,
  "validation_Yes_R": 0.7777777777777778,
  "validation_Yes_F1": 0.8166666666666169,
  "validation_accuracy": 0.8770949720670391,
  "validation_average_F1": 0.8621148459383254,
  "validation_loss": 0.4792466766508448,
  "best_epoch": 6,
  "best_validation_No_P": 0.8934426229508197,
  "best_validation_No_R": 0.9396551724137931,
  "best_validation_No_F1": 0.9159663865545719,
  "best_validation_Yes_P": 0.8771929824561403,
  "best_validation_Yes_R": 0.7936507936507936,
  "best_validation_Yes_F1": 0.8333333333332835,
  "best_validation_accuracy": 0.888268156424581,
  "best_validation_average_F1": 0.8746498599439276,
  "best_validation_loss": 0.45918026795413386,
  "test_No_P": 0.9104477611940298,
  "test_No_R": 0.953125,
  "test_No_F1": 0.9312977099236142,
  "test_Yes_P": 0.90625,
  "test_Yes_R": 0.8285714285714286,
  "test_Yes_F1": 0.8656716417909949,
  "test_accuracy": 0.9090909090909091,
  "test_average_F1": 0.8984846758573045,
  "test_loss": 0.24441279072449945
}
